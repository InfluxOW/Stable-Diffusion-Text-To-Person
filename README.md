# WIP: Stable Diffusion: text-to-person

> How to Generate High Quality Real People in Stable Diffusion

![Introduction.jpg](https://github.com/InfluxOW/Stable-Diffusion-Text-To-Person/blob/master/Images/Introduction.jpg)

Many of you might heard of `Stable Diffusion` and its ability to generate various high-quality images. However, not everyone is attracted by creating random pictures of cute catgirls and everything else. Don't you think it would be much more interesting if we could train the neural network to create images... of ourselves? Or our favorite actors and musicians? Or our deceased relatives? Specific individuals, in general, rather than some abstract images based on what the neural network was trained on. This is what we will be doing, attempting to determine the most optimal workflow and automate it as much as possible.

In the end, our task boils down to several subtasks:

- preparing a dataset for training the model;
- searching for the most optimal and versatile parameters for training, as well as directly training the model;
- generating images using the trained model and automating this process.

### CONTENT

Due to the huge number of images I have splitted the guide into different pages so read it in the specified order.

1. [Examples](https://github.com/InfluxOW/Stable-Diffusion-Text-To-Person/wiki/Examples)

2. [Dataset Preparation](https://github.com/InfluxOW/Stable-Diffusion-Text-To-Person/wiki/Dataset-Preparation)

3. [Model Training ‐ Introduction](https://github.com/InfluxOW/Stable-Diffusion-Text-To-Person/wiki/Model-Training--%E2%80%90--Introduction)

4. [Model Training ‐ Basics](https://github.com/InfluxOW/Stable-Diffusion-Text-To-Person/wiki/Model-Training--%E2%80%90--Basics)
